---
name: tech-longlist-verifier
description: tech-longlist-creatorで作成された技術ロングリストJSONファイルの内容が、情報ソースの原文に基づいた事実であるかを検証する。各項目について原文との照合を行い、ハルシネーション（推測・拡大解釈・一般論）を検出し、事実性スコアと詳細な検証レポートを生成する。研究開発部門の技術調査品質保証、情報の信頼性確認、レポート精度向上に使用する。
---

# Tech Longlist Verifier

tech-longlist-creatorで作成された技術ロングリストJSONファイルの事実性を検証し、情報ソースの原文に基づいているかを確認する品質保証スキル。

## Overview

このスキルは、技術ロングリストの各項目について、情報ソースURLの原文内容と照合し、以下を検証する:
- 記載内容が原文に存在するか
- 推測や拡大解釈が含まれていないか
- 一般論や確認できない情報が混入していないか
- 文章表現が適切か（である調、体言止め禁止など）

## Workflow

### Step 1: 入力ファイルの読み込み

以下のファイルを読み込む:
1. **技術ロングリストJSONファイル**: 検証対象のロングリスト（`{ID}_{組織名}.json`形式）
2. 各JSONファイルから以下の情報を抽出:
   - 基本情報: ID, タイトル, 概要1-4
   - 注目ポイント: 注目ポイント1-3
   - 技術・情報詳細: 技術開発の進展度, 主要情報ソースURL, 発表年または出願年, など
   - 組織情報: 組織名, 組織タイプ, 国名, 組織設立年, 組織URL
   - 情報ソース: 情報ソースURL_1-20
   - 分類: 動的フィールド

### Step 2: 情報ソースの取得

各JSONファイルについて:
1. **技術・情報詳細.主要情報ソースURL**および**情報ソース.情報ソースURL_1-20**から原文を取得
2. WebFetchツールを使用して実際のコンテンツを取得
3. 取得失敗の場合はその旨を記録

### Step 2-A: WebSearch代替検証（WebFetch失敗時）

WebFetchツールでの情報ソースURL取得が失敗した場合の代替検証方法:

#### WebSearch検証の実施
1. **企業名・製品名で検索**
   - 「企業名 + foodtech」または「企業名 + 主要製品名」で検索
   - 公式サイト、プレスリリース、信頼性の高いニュース記事を確認

2. **検証項目**
   - 組織名（正式名称）が正確か
   - 国名（本社所在地）が正確か
   - 組織設立年が正確か
   - タイトルに記載された技術名・製品名が実在するか
   - 事業内容・技術的特徴の記述が事実に基づいているか
   - 資金調達額・ラウンド種別が正確か（注目ポイント）
   - パートナーシップや提携情報が正確か
   - 技術開発の進展度が妥当か

3. **検証方法**
   - 各企業について1-2回のWebSearch検索を実施
   - 検索結果から公式情報、ニュース記事、プレスリリースを確認
   - 記載内容と検索結果を照合
   - 不一致や誤りを特定（特に以下に注意）:
     - 資金調達額の誤り（金額・ラウンド種別）
     - 事業内容の変更（ピボット）の未反映
     - 開発段階の過大評価

4. **情報源の信頼性レベル**
   - **高信頼性**: 公式ウェブサイト、公式プレスリリース、企業登録データベース
   - **中信頼性**: TechCrunch、vegconomist、Restaurant Business Online等の信頼性の高いメディア
   - **補助的**: LinkedIn、Crunchbase、PitchBook

5. **検証結果の記録**
   - 検証ステータス: "verified" | "issues_found" | "unable_to_verify"
   - 正確性スコア: 0-100点
   - 発見されたエラー（フィールド、現在値、正確な値、重大度）
   - 使用したWebSearch検索クエリ
   - 主要情報源のURL

### Step 3: 事実性検証

各項目について以下を検証:

#### 3.1 タイトルの検証
- 製品名/技術名が原文に存在するか
- 技術的特徴の記述が原文に基づいているか
- マーケティング的誇張表現が含まれていないか

#### 3.2 概要1の検証
- 組織名が原文と一致するか
- 開発/研究/販売の事実が原文に記載されているか
- 国名情報が正確か

#### 3.3 概要2の検証
- 材料、デバイス、サービスの原理・機能・構造の記述が原文に存在するか
- 技術的詳細が原文と一致するか
- 推測や拡大解釈が含まれていないか

#### 3.4 概要3の検証
- 成果や特性のデータが原文に明記されているか
- 数値データが正確か
- 検証機関名などが正確か

#### 3.5 概要4の検証
- 用途情報が原文に記載されているか
- ターゲット情報が正確か

#### 3.6 注目ポイント1-3の検証
- 課題、背景が原文に記載されているか
- 新規性、進歩性、優位性の記述が原文に基づいているか
- 特許番号、論文情報が正確か

#### 3.7 技術情報詳細の検証
- 技術開発の進展度が原文の記述と整合するか
- 発表年/出願年が正確か

#### 3.8 組織情報の検証
- 組織名（英語正式名称）が正確か
- 組織タイプ、国名、設立年、URLが正確か

### Step 4: ハルシネーション検出

以下のパターンを検出:

#### 禁止表現の検出
- 世界初
- 革新的
- 画期的
- 完全に
- 新時代の

#### 推測表現の検出
- 「～と考えられる」
- 「～の可能性がある」
- 「～と推測される」

#### 一般論の混入検出
- 原文に記載のない業界動向
- 原文に記載のない一般的な課題
- 確認できない比較情報

#### 拡大解釈の検出
- 原文の表現を超えた記述
- 原文にない因果関係の主張
- 数値の誇張や曲解

### Step 5: 文章表現の検証

tech-longlist-creatorの文章作成ガイドラインに従っているかを確認:

#### 文体チェック
- [ ] である調で統一されているか
- [ ] 体言止めを使用していないか

#### 表記チェック
- [ ] 全角括弧（）を使用しているか
- [ ] 数字と単位の間に半角スペースがあるか
- [ ] 商標記号を除去しているか

#### 用語チェック
- [ ] 専門用語に説明を付けているか
- [ ] 略語を初出時に定義しているか
- [ ] 用語が統一されているか
- [ ] 組織名を英語で記載しているか

#### 主語チェック
- [ ] 概要1で組織名を主語としているか
- [ ] 概要2-3で「同技術」「同サービス」などで統一しているか

#### 文字数チェック
- [ ] 各項目の文字数制限を守っているか

### Step 6: 事実性スコアリング

各項目について以下の基準でスコアリング:

#### スコア定義
- **100点**: 完全に原文に基づいており、推測や拡大解釈なし
- **80-99点**: ほぼ原文に基づいているが、軽微な表現の調整あり
- **60-79点**: 原文に基づいているが、一部推測や補足情報あり
- **40-59点**: 原文の情報と推測が混在
- **20-39点**: 推測や拡大解釈が多く含まれる
- **0-19点**: 原文に基づいていない、またはハルシネーション

#### 評価基準
各項目について以下を評価:
1. **原文存在性** (40点): 記載内容が原文に明記されているか
2. **正確性** (30点): 数値、固有名詞、事実関係が正確か
3. **客観性** (20点): 推測や拡大解釈がないか
4. **表現適切性** (10点): 文体、用語、表記が適切か

### Step 7: 検証レポート生成

以下の形式で検証レポートを生成:

#### レポート構成

```markdown
# 技術ロングリスト検証レポート

## サマリー
- 検証日時: YYYY-MM-DD HH:MM:SS
- 総行数: N行
- 平均事実性スコア: XX.X点
- 問題検出数: N件
- 重大問題数: N件

## 総合評価
[A/B/C/D評価と総評]

## 詳細検証結果

### ID: [調査対象ID]
#### 基本情報
- タイトル: [タイトル]
- 組織名: [組織名]
- 主要情報ソースURL: [URL]

#### 事実性スコア: XX点 / 100点

#### 検証結果

##### タイトル [スコア: XX/100]
- ✅ 原文確認: [確認結果]
- ⚠️ 問題点: [問題があれば記載]
- 📝 原文引用: "[原文の該当箇所]"
- 💡 推奨修正: [修正が必要な場合]

##### 概要1 [スコア: XX/100]
- ✅ 原文確認: [確認結果]
- ⚠️ 問題点: [問題があれば記載]
- 📝 原文引用: "[原文の該当箇所]"
- 💡 推奨修正: [修正が必要な場合]

##### 概要2 [スコア: XX/100]
[同様の形式で各項目を検証]

##### 概要3 [スコア: XX/100]
[同様の形式]

##### 概要4 [スコア: XX/100]
[同様の形式]

##### 注目ポイント1 [スコア: XX/100]
[同様の形式]

##### 注目ポイント2 [スコア: XX/100]
[同様の形式]

##### 注目ポイント3 [スコア: XX/100]
[同様の形式]

##### 技術情報詳細 [スコア: XX/100]
[同様の形式]

##### 組織情報 [スコア: XX/100]
[同様の形式]

#### ハルシネーション検出
- 禁止表現: [検出された表現のリスト]
- 推測表現: [検出された表現のリスト]
- 一般論混入: [検出された箇所のリスト]
- 拡大解釈: [検出された箇所のリスト]

#### 文章表現の問題
- 文体の問題: [である調、体言止めなどの問題]
- 表記の問題: [括弧、スペース、商標記号などの問題]
- 用語の問題: [専門用語、略語、組織名などの問題]
- 主語の問題: [主語の統一に関する問題]
- 文字数の問題: [文字数制限違反]

#### 総合コメント
[この行の全体的な評価と改善提案]

---

[次の行についても同様に検証]

```

### Step 8: 改善提案の生成

検出された問題について、以下を提案:

#### 1. 事実性の改善
- 原文に基づいた正確な記述への修正案
- 推測部分の削除または原文に基づく記述への置き換え
- 拡大解釈の修正

#### 2. 文章表現の改善
- 文体の統一（である調）
- 体言止めの修正
- 表記の修正（括弧、スペース、商標記号）
- 用語の統一と定義の追加

#### 3. 情報の補完
- 原文に存在するが記載されていない重要情報
- より正確な表現への修正提案

## Verification Criteria

### 事実性評価の基準

#### 原文存在性 (40点)
- **40点**: 記載内容が原文に明確に記載されている
- **30点**: 記載内容が原文から合理的に推測できる
- **20点**: 記載内容が原文に部分的に記載されている
- **10点**: 記載内容が原文にほとんど存在しない
- **0点**: 記載内容が原文に全く存在しない

#### 正確性 (30点)
- **30点**: 数値、固有名詞、事実関係が完全に正確
- **20点**: 軽微な誤りがある（表記のみの違いなど）
- **10点**: 重大な誤りがある（数値の間違いなど）
- **0点**: 事実と異なる情報が記載されている

#### 客観性 (20点)
- **20点**: 推測や拡大解釈が全くない
- **15点**: 軽微な推測や補足がある
- **10点**: 推測や拡大解釈が含まれている
- **5点**: 推測や拡大解釈が多く含まれている
- **0点**: ほぼ推測で構成されている

#### 表現適切性 (10点)
- **10点**: 文体、用語、表記が完全に適切
- **7点**: 軽微な表現の問題がある
- **5点**: 複数の表現の問題がある
- **3点**: 重大な表現の問題がある
- **0点**: 文章表現が不適切

### 総合評価の基準

#### A評価 (90-100点)
- 原文に完全に基づいており、推測や拡大解釈なし
- 文章表現が適切で、ガイドラインに完全準拠
- 軽微な修正のみで使用可能

#### B評価 (70-89点)
- ほぼ原文に基づいているが、一部改善の余地あり
- 文章表現はおおむね適切
- 部分的な修正で使用可能

#### C評価 (50-69点)
- 原文に基づいているが、推測や補足情報が混在
- 文章表現に複数の問題あり
- 相当の修正が必要

#### D評価 (0-49点)
- 推測や拡大解釈が多く含まれる
- 文章表現が不適切
- 大幅な修正または再作成が必要

## Output Format

### 検証レポートファイル

以下のファイルを生成:

1. **検証レポート (Markdown)**: `verification_report_YYYYMMDD_HHMMSS.md`
   - 人間が読みやすい詳細レポート
   - 問題箇所の具体的な指摘と改善提案

2. **検証結果 (JSON)**: 各対象ごとにJSONファイルを生成
   - ファイル名: `{ID}_{組織名}_verified.json`
   - 元のロングリストJSONに検証結果を追加
   - 各項目の事実性スコア
   - 問題の有無フラグ
   - 簡潔な問題指摘
   - 構造例:
   ```json
   {
     "基本情報": { ... },
     "注目ポイント": { ... },
     "技術・情報詳細": { ... },
     "組織情報": { ... },
     "情報ソース": { ... },
     "分類": { ... },
     "検証結果": {
       "検証日時": "2024-01-01T12:00:00",
       "総合スコア": 85,
       "評価": "B",
       "項目別スコア": {
         "タイトル": 90,
         "概要1": 85,
         "概要2": 80,
         "概要3": 85,
         "概要4": 90,
         "注目ポイント1": 85,
         "注目ポイント2": 80,
         "注目ポイント3": 85,
         "技術情報詳細": 90,
         "組織情報": 95
       },
       "ハルシネーション検出": {
         "禁止表現": [],
         "推測表現": [],
         "一般論混入": [],
         "拡大解釈": []
       },
       "問題指摘": [
         {
           "項目": "概要2",
           "重大度": "中",
           "問題": "推測表現が含まれる",
           "推奨修正": "原文に基づく記述に修正"
         }
       ],
       "使用情報源": [
         "https://example.com/source1",
         "https://example.com/source2"
       ]
     }
   }
   ```

3. **サマリーレポート (JSON)**: `verification_summary_YYYYMMDD_HHMMSS.json`
   - 全体の検証結果サマリー
   - 機械可読な検証結果
   - スコア統計情報
   - 問題パターンの集計

## Usage Example

```python
# 検証の実行
import json
import glob
from pathlib import Path
from tech_longlist_verifier import verify_longlist_json

# JSONファイルのディレクトリ指定
json_dir = Path('./longlist_output')
json_files = glob.glob(str(json_dir / '*.json'))

# 各JSONファイルを検証
verification_results = []
for json_file in json_files:
    # JSONファイルの読み込み
    with open(json_file, 'r', encoding='utf-8') as f:
        longlist_data = json.load(f)

    # 検証実行
    result = verify_longlist_json(
        longlist_data=longlist_data,
        json_file_path=json_file,
        output_dir='./verification_results',
        verbose=True
    )

    verification_results.append(result)

    # 検証済みJSONの保存（元のJSONに検証結果を追加）
    verified_file = json_file.replace('.json', '_verified.json')
    with open(verified_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

# 全体結果の確認
avg_score = sum(r['検証結果']['総合スコア'] for r in verification_results) / len(verification_results)
total_issues = sum(len(r['検証結果']['問題指摘']) for r in verification_results)

print(f"検証対象ファイル数: {len(verification_results)}")
print(f"平均スコア: {avg_score:.1f}点")
print(f"問題検出数: {total_issues}件")
```

## Key Features

### 1. 包括的な事実性検証
- 全項目について原文との照合を実施（WebFetch）
- **WebSearch代替検証**: WebFetch失敗時はWebSearchで公開情報と照合
- 文単位での詳細な比較
- 数値、固有名詞の正確性確認

### 2. ハルシネーション検出
- 禁止表現の自動検出
- 推測・拡大解釈の識別
- 一般論混入の検出
- **資金調達情報の誤り検出**: 金額・ラウンド種別の正確性確認
- **事業ピボットの検出**: 事業内容の変更・方向転換の未反映を特定

### 3. 定量的評価
- 項目ごとの事実性スコア
- 総合評価（A/B/C/D）
- 問題の重大度分類（高・中・低）
- **正確性スコア**: 0-100点での定量評価

### 4. 実用的な改善提案
- 原文に基づく修正案の提示
- 文章表現の改善提案
- 追加すべき情報の提案
- **WebSearch検証結果に基づく修正**: 公開情報との不一致を修正

### 5. 複数形式の出力
- 人間向け詳細レポート (Markdown)
- 個別検証結果 (JSON): 各対象の検証済みデータ
- 機械可読サマリー (JSON): 全体統計と問題パターン
- **WebSearch検証結果 (JSON)**: 検証ステータス、エラー詳細、情報源URL

## Verification Process Details

### 原文照合の方法

#### 1. 完全一致の確認
- 記載内容が原文に文字列として存在するか確認
- 表現のゆれを考慮した照合

#### 2. 意味的一致の確認
- 記載内容が原文の意味と一致するか確認
- 言い換えや要約が適切か評価

#### 3. 推測の検出
- 原文に明記されていない情報の検出
- 「可能性」「考えられる」などの表現の検出

#### 4. 拡大解釈の検出
- 原文の表現を超えた記述の検出
- 原文にない因果関係の主張の検出

### エラーハンドリング

#### 情報ソースURL取得失敗時
- 取得失敗を記録
- スコアを「検証不可」とマーク
- 代替URLでの検証を試行

#### 原文が不明瞭な場合
- 複数の解釈が可能な場合は保留
- 他の情報ソースとの整合性を確認
- 検証コメントに不確実性を記載

## Quality Assurance

### 検証の品質保証

#### 二重確認の実施
重要な項目については:
- 複数の情報ソースとの照合
- 数値データの再確認
- 固有名詞の正確性確認

#### 検証者バイアスの排除
- 事実のみに基づく評価
- 主観的判断を避ける
- 明確な基準に基づく採点

#### 継続的改善
- 検証結果のフィードバック収集
- 検証基準の継続的見直し
- 検出パターンの学習と改善

## Notes

- このスキルは大量のWebFetch操作を伴うため、処理に時間がかかる場合がある
- 各JSONファイルの検証が完了次第、検証済みJSONファイル（`_verified.json`）を即座に出力
- 情報ソースURLにアクセスできない場合、その旨を記録して検証を継続
- **WebFetch失敗時の代替手段**: WebSearchツールを使用して公開情報と照合することで、WebFetchが403 Forbiddenエラー等で失敗した場合でも事実性検証が可能
- **WebSearch検証の強み**:
  - ボット制限がある公式サイトでも検索エンジン経由で情報取得可能
  - ニュース記事、プレスリリース等の複数の独立したソースから情報確認
  - 企業の方向転換（ピボット）や最新の資金調達情報など、公式サイト以外の情報も捕捉
  - 資金調達額の誤り、ラウンド種別の誤りなど、数値情報の正確性を高精度で検証
- 原文が複数の情報源に分散している場合、可能な限り全てを確認
- 専門的な技術内容については、原文の表現を尊重した評価を行う
- 検証結果はあくまで参考情報であり、最終的な判断は人間が行うべき
- **WebSearch検証の限界**: 検索結果に表示されない内部情報や機密情報は検証不可能なため、公開情報のみに基づく検証となる
- **JSON出力により、処理の途中経過が保存され、エラー発生時も完了済みの検証データが失われない**

## Best Practices

### 検証前の準備
1. 全ての情報ソースURLが有効かを事前確認
2. 検証対象のロングリストが最新版であることを確認
3. 必要に応じてVPN等でアクセス制限を回避

### 検証中の注意点
1. 原文の文脈を考慮した評価
2. 専門用語の定義を確認
3. 数値データの単位と精度を確認
4. 組織名の表記ゆれに注意

### 検証後のフォロー
1. 検証レポートの内容を精査
2. 重大な問題から優先的に修正
3. 修正後に再検証を実施
4. 検証結果を次回の改善に活用
